{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\远垂\\scoop\\apps\\python\\current\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "PATH = './model.pt'\n",
    "if torch.cuda.is_available():\n",
    "    torch.device('cuda:0')\n",
    "    \n",
    "class LinearClassifier(nn.Module):\n",
    "    # define a linear classifier\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        # inchannels: dimenshion of input data. For example, a RGB image [3x32x32] is converted to vector [3 * 32 * 32], so dimenshion=3072\n",
    "        # out_channels: number of categories. For CIFAR-10, it's 10\n",
    "        self.linear = nn.Linear(in_channels, out_channels)\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "class FCNN(nn.Module):\n",
    "    # def a full-connected neural network classifier\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels) -> None:\n",
    "        super().__init__()\n",
    "        # inchannels: dimenshion of input data. For example, a RGB image [3x32x32] is converted to vector [3 * 32 * 32], so dimenshion=3072\n",
    "        # hidden_channels\n",
    "        # out_channels: number of categories. For CIFAR-10, it's 10\n",
    "\n",
    "        # full connected layer\n",
    "        # activation function\n",
    "        # full connected layer\n",
    "        # ......\n",
    "        self.fc1 = nn.Linear(in_channels, hidden_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x: torch.Tensor): \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "def svmloss(scores: torch.Tensor, label: torch.Tensor):\n",
    "    '''\n",
    "    compute SVM loss\n",
    "    input:\n",
    "        scores: output of model \n",
    "        label: true label of data\n",
    "    return:\n",
    "        svm loss\n",
    "    '''\n",
    "    correct_scores = scores[torch.arange(scores.size(0)), label].view(-1, 1)\n",
    "    margins = torch.clamp(scores - correct_scores + 1, min=0)\n",
    "    margins[torch.arange(scores.size(0)), label] = 0  # Ignore the correct class\n",
    "    loss = margins.sum() / scores.size(0)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def crossentropyloss(logits: torch.Tensor, label: torch.Tensor):\n",
    "    '''\n",
    "    Object: implement Cross Entropy loss function\n",
    "    input:\n",
    "        logits: output of model, (unnormalized log-probabilities). shape: [batch_size, c]\n",
    "        label: true label of data. shape: [batch_size]\n",
    "    return: \n",
    "        cross entropy loss\n",
    "    '''\n",
    "    max_logits = torch.max(logits, dim=1, keepdim=True).values\n",
    "    exp_logits = torch.exp(logits - max_logits)\n",
    "    softmax_probs = exp_logits / (exp_logits.sum(dim=1, keepdim=True) + 1e-10)\n",
    "    loss = -torch.log(softmax_probs[torch.arange(logits.size(0)), label] + 1e-10).mean()\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_function, optimizer, scheduler, args):\n",
    "    '''\n",
    "    Model training function\n",
    "    input: \n",
    "        model: linear classifier or full-connected neural network classifier\n",
    "        loss_function: SVM loss of Cross-entropy loss\n",
    "        optimizer: Adamw or SGD\n",
    "        scheduler: step or cosine\n",
    "        args: configuration\n",
    "    '''\n",
    "    if os.path.exists(PATH):\n",
    "        checkpoint = torch.load(PATH)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    # create dataset\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    batch_size = 4\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform)\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "    # create dataloader\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    # for-loop \n",
    "    epoch_cnt = 2\n",
    "    running_loss = 0.0\n",
    "    for epoch in range(epoch_cnt):\n",
    "        # train\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        with tqdm(total=len(trainloader), desc=f'Epoch: {epoch+1}/{epoch_cnt}', unit='batch') as pbar:\n",
    "            for i, data in enumerate(trainloader):\n",
    "                inputs, labels = data\n",
    "                inputs = nn.Flatten()(inputs)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward\n",
    "                outputs = model(inputs) \n",
    "                # loss backward\n",
    "                loss = loss_function(outputs, labels)\n",
    "                loss.backward()\n",
    "                # optimize\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                pbar.update(1)\n",
    "                if i % 100 == 0:\n",
    "                    pbar.set_postfix(loss=loss.item())\n",
    "                if i == 2000:\n",
    "                    break\n",
    "        # adjust learning rate\n",
    "        scheduler.step()\n",
    "        # test\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            # forward\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                images = nn.Flatten()(images)\n",
    "                outputs = model(images)\n",
    "                images = nn.Flatten()(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
    "\n",
    "    # save checkpoint (Tutorial: https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html)\n",
    "    torch.save(\n",
    "        {\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict()\n",
    "        }, PATH)\n",
    "\n",
    "def test(model, loss_function, args):\n",
    "    '''\n",
    "    input: \n",
    "        model: linear classifier or full-connected neural network classifier\n",
    "        loss_function: SVM loss of Cross-entropy loss\n",
    "    '''\n",
    "    # load checkpoint (Tutorial: https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html)\n",
    "    checkpoint = torch.load(PATH)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    # create testing dataset\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    batch_size = 4\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "    # create dataloader\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    # test\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        # forward\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, args:dict):\n",
    "        self.model = args['model']\n",
    "        self.optimizer = args['optimizer']\n",
    "        self.scheduler = args['scheduler']\n",
    "        self.run = args['run']\n",
    "        self.loss = args['loss']\n",
    "setting = {\n",
    "    'model': 'fcnn',\n",
    "    'optimizer': 'adamw',\n",
    "    'scheduler': 'step',\n",
    "    'loss': 'crossentropyloss',\n",
    "    'run': 'train'\n",
    "}\n",
    "args = Args(setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2:  16%|█▌        | 2001/12500 [01:17<06:46, 25.81batch/s, loss=2.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 26 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/2:   7%|▋         | 930/12500 [00:39<06:59, 27.56batch/s, loss=1.98] "
     ]
    }
   ],
   "source": [
    "# create model\n",
    "if args.model == 'linear':\n",
    "    model = LinearClassifier(3 * 32 * 32, 10)\n",
    "elif args.model == 'fcnn':\n",
    "    model = FCNN(3 * 32 * 32, 1024, 10)\n",
    "else: \n",
    "    raise AssertionError\n",
    "\n",
    "# create optimizer\n",
    "if args.optimizer == 'adamw':\n",
    "    # create Adamw optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "elif args.optimizer == 'sgd':\n",
    "    # create SGD optimizer\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.01)\n",
    "else:\n",
    "    raise AssertionError\n",
    "\n",
    "# create scheduler\n",
    "if args.scheduler == 'step':\n",
    "    # create torch.optim.lr_scheduler.StepLR scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "elif args.scheduler == 'ncosie':\n",
    "    # create torch.optim.lr_scheduler.CosineAnnealingLR scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "else:\n",
    "    raise AssertionError\n",
    "\n",
    "if args.run == 'train':\n",
    "    train(model, eval(args.loss), optimizer, scheduler, args)\n",
    "elif args.run == 'test':\n",
    "    test(model, eval(args.loss), args)\n",
    "else: \n",
    "    raise AssertionError"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
